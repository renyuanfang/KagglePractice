{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'sample_submission.csv', 'train']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout, Lambda, Input, Concatenate, concatenate\n",
    "from keras.models import Model\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(\"../input/train/train\")\n",
    "labels = []\n",
    "for file in filenames:\n",
    "    category = file.split('.')[0]\n",
    "    if category == 'cat':\n",
    "        labels.append('cat')\n",
    "    else:\n",
    "        labels.append('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'label': labels\n",
    "})\n",
    "train_df, validation_df = train_test_split(df, test_size=0.1, random_state = 42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validation_df = validation_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_num = len(train_df)\n",
    "validation_num = len(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_image_generator(generator, df, directory, batch_size,\n",
    "                        x_col = 'filename', y_col = None, model = None, shuffle = False,\n",
    "                        img_size1 = (224, 224), img_size2 = (299,299)):\n",
    "    gen1 = generator.flow_from_dataframe(\n",
    "        df,\n",
    "        directory,\n",
    "        x_col = x_col,\n",
    "        y_col = y_col,\n",
    "        target_size = img_size1,\n",
    "        class_mode = model,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        seed = 1)\n",
    "    gen2 = generator.flow_from_dataframe(\n",
    "        df,\n",
    "        directory,\n",
    "        x_col = x_col,\n",
    "        y_col = y_col,\n",
    "        target_size = img_size2,\n",
    "        class_mode = model,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        seed = 1)\n",
    "    \n",
    "    while True:\n",
    "        X1i = gen1.next()\n",
    "        X2i = gen2.next()\n",
    "        if y_col:\n",
    "            yield [X1i[0], X2i[0]], X1i[1]  #X1i[1] is the label\n",
    "        else:\n",
    "            yield [X1i, X2i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#test if the generator generates same images with two different sizes\\n\\nex_df = pd.DataFrame()\\nex_df['filename'] = filenames[:5]\\nex_df['label'] = labels[:5]\\nex_df.head()\\n\\ntrain_aug_datagen = ImageDataGenerator(\\n    rotation_range = 20,\\n    shear_range = 0.1,\\n    zoom_range = 0.2,\\n    width_shift_range = 0.1,\\n    height_shift_range = 0.1,\\n    horizontal_flip = True\\n)\\ne1 = two_image_generator(train_aug_datagen, ex_df, '../input/train/train/',\\n                                      batch_size = 2, y_col = 'label',\\n                                      model = 'binary', shuffle = True)\\n\\nfig = plt.figure(figsize = (10,10))\\nbatches = 0\\nrows = 4\\ncols = 5\\ni = 0\\nj = 0\\nindices_a = [1, 2, 3, 4, 5, 11, 12, 13, 14, 15]\\nindices_b = [6, 7, 8, 9, 10, 16, 17, 18, 19, 20]\\nfor [x_batch, x_batch2], y_batch in e1:\\n    for image in x_batch:\\n        fig.add_subplot(rows, cols, indices_a[i])\\n        i += 1\\n        plt.imshow(image.astype('uint8'))\\n        \\n    for image in x_batch2:\\n        fig.add_subplot(rows, cols, indices_b[j])\\n        j += 1\\n        plt.imshow(image.astype('uint8'))\\n    \\n    batches += 1\\n    if batches >= 6:\\n        break\\nplt.show()\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#test if the generator generates same images with two different sizes\n",
    "\n",
    "ex_df = pd.DataFrame()\n",
    "ex_df['filename'] = filenames[:5]\n",
    "ex_df['label'] = labels[:5]\n",
    "ex_df.head()\n",
    "\n",
    "train_aug_datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    shear_range = 0.1,\n",
    "    zoom_range = 0.2,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "e1 = two_image_generator(train_aug_datagen, ex_df, '../input/train/train/',\n",
    "                                      batch_size = 2, y_col = 'label',\n",
    "                                      model = 'binary', shuffle = True)\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "batches = 0\n",
    "rows = 4\n",
    "cols = 5\n",
    "i = 0\n",
    "j = 0\n",
    "indices_a = [1, 2, 3, 4, 5, 11, 12, 13, 14, 15]\n",
    "indices_b = [6, 7, 8, 9, 10, 16, 17, 18, 19, 20]\n",
    "for [x_batch, x_batch2], y_batch in e1:\n",
    "    for image in x_batch:\n",
    "        fig.add_subplot(rows, cols, indices_a[i])\n",
    "        i += 1\n",
    "        plt.imshow(image.astype('uint8'))\n",
    "        \n",
    "    for image in x_batch2:\n",
    "        fig.add_subplot(rows, cols, indices_b[j])\n",
    "        j += 1\n",
    "        plt.imshow(image.astype('uint8'))\n",
    "    \n",
    "    batches += 1\n",
    "    if batches >= 6:\n",
    "        break\n",
    "plt.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add data_augmentation\n",
    "train_aug_datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    shear_range = 0.1,\n",
    "    zoom_range = 0.2,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "train_generator = two_image_generator(train_aug_datagen, train_df, '../input/train/train/',\n",
    "                                      batch_size = batch_size, y_col = 'label',\n",
    "                                      model = 'binary', shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = two_image_generator(validation_datagen, validation_df,\n",
    "                                           '../input/train/train/', batch_size = batch_size,\n",
    "                                           y_col = 'label',model = 'binary', shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(MODEL, img_size, lambda_fun = None):\n",
    "    inp = Input(shape = (img_size[0], img_size[1], 3))\n",
    "    x = inp\n",
    "    if lambda_fun:\n",
    "        x = Lambda(lambda_fun)(x)\n",
    "    \n",
    "    base_model = MODEL(input_tensor = x, weights = 'imagenet', include_top = False, pooling = 'avg')\n",
    "        \n",
    "    model = Model(inp, base_model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 2s 0us/step\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 6s 0us/step\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 2s 0us/step\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 512)          14714688    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 2048)         23587712    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 2048)         21802784    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4608)         0           model_1[1][0]                    \n",
      "                                                                 model_2[1][0]                    \n",
      "                                                                 model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4608)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            4609        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 60,109,793\n",
      "Trainable params: 4,609\n",
      "Non-trainable params: 60,105,184\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define vgg + resnet50 + densenet\n",
    "model1 = create_base_model(vgg16.VGG16, (224, 224), vgg16.preprocess_input)\n",
    "model2 = create_base_model(resnet50.ResNet50, (224, 224), resnet50.preprocess_input)\n",
    "model3 = create_base_model(inception_v3.InceptionV3, (299, 299), inception_v3.preprocess_input)\n",
    "model1.trainable = False\n",
    "model2.trainable = False\n",
    "model3.trainable = False\n",
    "\n",
    "inpA = Input(shape = (224, 224, 3))\n",
    "inpB = Input(shape = (299, 299, 3))\n",
    "out1 = model1(inpA)\n",
    "out2 = model2(inpA)\n",
    "out3 = model3(inpB)\n",
    "\n",
    "x = Concatenate()([out1, out2, out3])                \n",
    "x = Dropout(0.6)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "multiple_pretained_model = Model([inpA, inpB], x)\n",
    "\n",
    "multiple_pretained_model.compile(loss = 'binary_crossentropy',\n",
    "                          optimizer = 'rmsprop',\n",
    "                          metrics = ['accuracy'])\n",
    "\n",
    "multiple_pretained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='dogcat.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "Found 2500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "Found 22500 images belonging to 2 classes.\n",
      "Found 22500 images belonging to 2 classes.\n",
      "351/351 [==============================] - 847s 2s/step - loss: 0.1669 - acc: 0.9407 - val_loss: 0.0245 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02447, saving model to dogcat.weights.best.hdf5\n",
      "Epoch 2/5\n",
      "351/351 [==============================] - 797s 2s/step - loss: 0.0799 - acc: 0.9710 - val_loss: 0.0210 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02447 to 0.02100, saving model to dogcat.weights.best.hdf5\n",
      "Epoch 3/5\n",
      "351/351 [==============================] - 799s 2s/step - loss: 0.0780 - acc: 0.9735 - val_loss: 0.0262 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02100\n",
      "Epoch 4/5\n",
      "351/351 [==============================] - 801s 2s/step - loss: 0.0755 - acc: 0.9753 - val_loss: 0.0591 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02100\n",
      "Epoch 5/5\n",
      "351/351 [==============================] - 801s 2s/step - loss: 0.0808 - acc: 0.9736 - val_loss: 0.1512 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8458ffdd30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_pretained_model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = 5,\n",
    "    steps_per_epoch = train_num // batch_size,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_num // batch_size,\n",
    "    verbose = 1,\n",
    "    callbacks = [checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_pretained_model.load_weights('dogcat.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(\"../input/test/test\")\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "num_test = len(test_df)\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "test_generator = two_image_generator(test_datagen, test_df, '../input/test/test/', batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images.\n",
      "Found 12500 images.\n"
     ]
    }
   ],
   "source": [
    "prediction = multiple_pretained_model.predict_generator(test_generator, \n",
    "                                         steps=np.ceil(num_test/batch_size))\n",
    "prediction = prediction.clip(min = 0.005, max = 0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('../input/sample_submission.csv')\n",
    "for i, fname in enumerate(test_filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    submission_df.at[index-1, 'label'] = prediction[i]\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995\n",
       "2   3  0.995\n",
       "3   4  0.995\n",
       "4   5  0.005"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
